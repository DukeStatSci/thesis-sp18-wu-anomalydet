#Matrix Techniques for Anomaly Detection
MAYBE PUT LIT REVIEW WITH EACH SECTION?

##Ports Combination Matrix/Tensor

```{r}
#set counts
s_num = 25
d_num = 25
combo_num = 20

#get freqs
Sport_table = table(Sport)
Sport_table = as.data.frame(Sport_table)
Sport_table = Sport_table[order(-Sport_table$Freq),]
top_Sport = (head(Sport_table$Sport, s_num))

#get freqs
Dport_table = table(Dport)
Dport_table = as.data.frame(Dport_table)
Dport_table = Dport_table[order(-Dport_table$Freq),]
top_Dport = (head(Dport_table$Dport, d_num))

#subset data
argus_maxes = argus[is.element(Sport, top_Sport) & is.element(Dport, top_Dport), ]
argus_maxes = transform(argus_maxes,
                        Sport = as.numeric(as.character(Sport)),
                        Dport = as.numeric(as.character(Dport)))
max_combinations = as.data.frame(table(argus_maxes$Sport, argus_maxes$Dport))

top_combinations = head(max_combinations[order(-max_combinations$Freq),], combo_num)
top_combinations$Sport = top_combinations$Var1
top_combinations$Dport = top_combinations$Var2
top_combinations$Var1 = NULL
top_combinations$Var2 = NULL
top_combinations = transform(top_combinations,
                             Sport = as.numeric(as.character(Sport)),
                             Dport = as.numeric(as.character(Dport)))

extract_intersection = function(sport, dport){
  argus_subset = argus[Sport == sport & Dport == dport,]
  return (argus_subset)
}

generate_combinations_matrix = function(top_combinations){
  n = dim(top_combinations)[1]
  combinations = c()
  for (i in 1:n){
    sport = as.numeric(top_combinations[i,]$Sport)
    dport = as.numeric(top_combinations[i,]$Dport)
    combo = extract_intersection(sport, dport)
    combinations = c(combinations, list(combo))
  }
  return (combinations)
}
combinations = generate_combinations_matrix(top_combinations)
```

```{r,include=FALSE}
# combinations = readRDS("data/combinations.rds")
```

We now have a matrix built with the most common Sport and Dport combinations. Each entry in the matrix contains all of the observations that correspond to that Sport and Dport combination. We can now perform testing on each group using normal transformations and principal component analysis to see if there are any trends between groups.

##Principal Component Analysis
```{r}
pca_analysis = function(SrcBytes, SrcPkts, DstBytes, DstPkts){
  pca_cont_vars = cbind(SrcBytes, SrcPkts, DstBytes, DstPkts)
  pca = prcomp(pca_cont_vars, center = TRUE, scale. = TRUE)
  print(pca$rotation)
  print((summary(pca)))
  #screeplot(pca, type="lines",col=3)
  g = ggbiplot(pca, obs.scale = 1, var.scale = 1,
                ellipse = TRUE,
                circle = TRUE)
  g = g + scale_color_discrete(name = '')
  g = g + theme(legend.direction = 'horizontal',
                 legend.position = 'top')
  print(g)
  return(pca$rotation)
}
```

### Investigating Combinations
```{r}
combo_num = 10
for (i in 1:combo_num){
  combo_table = combinations[i]
  combo_table = transform(combo_table,
                          SrcBytes = as.numeric(SrcBytes),
                          SrcPkts = as.numeric(SrcPkts),
                          DstBytes = as.numeric(DstBytes),
                          DstPkts = as.numeric(DstPkts))
  cat("Sport:", combo_table$Sport[1],"\t")
  cat("Dport:", combo_table$Dport[1],"\n")
  SrcBytes_norm =  nscore(combo_table$SrcBytes)$nscore
  SrcPkts_norm =  nscore(combo_table$SrcPkts)$nscore
  DstBytes_norm =  nscore(combo_table$DstBytes)$nscore
  DstPkts_norm =  nscore(combo_table$DstPkts)$nscore
  pca_analysis(SrcBytes_norm, SrcPkts_norm, DstBytes_norm, DstPkts_norm)
}
```

Zeroes in the dataset causing the patterns in the 2nd principal component. Normal scores dont work very well if there are ties in the data.

## Matrix Completion via Singular Value Decomposition

There are $m$ source ports and $n$ destination ports. $Y \in {\rm I\!R}^{m \times n}$, is the matrix that stores the means of the combinations of source ports and destination ports. $Y$ has a lot of missingness because not every source port interacts with every destination port. $F \in {\rm I\!R}^{m \times n}$ is a sparse matrix that represents the frequencies of combinations, i.e $F[32242,12312]$ represents the number of observations for the 32242 12312 port interaction. $M \in {\rm I\!R}^{m \times n}$ represents a boolean matrix of whether the corresponding $Y$ values are missing. $Y[M]$ represents all of the missing values of $Y$.

There are multiple steps to the matrix completion process:
Impute the initial values for the missing $y_{i,j}$ observations $1 \leq i \leq m, 1 \leq j \leq n$: In general an additive model is applicable: $$y_{i,j} = \mu + a_i + b_j + \epsilon_{i,j}$$ where $\epsilon \in N(0,\sigma^2)$, $\mu$ is the overall mean, $a_i$ is the row mean, and $b_j$ is column mean. An analysis of variance (ANOVA) imputation is used to fill in the initial values, $y_{i,j}$. Ignoring the missing values for now, let $y_{..}$ denote the empirical overall mean, $y_{i.}$ denote the empirical row mean, and $y_{.j}$ denote the column mean. $$y_{i,j} = y_{..} + (y_{i.}-y{..}) + (y_{.j}-y_{..}) = y_{i.} + y_{.j} - y{..}$$

The repeated imputation procedure solves $Y^{(s)}[M] = R_k(Y^{(s-1)})[M]$ where $R_k$ is the best rank-k approximation for the $s$-th step. For each step $(s)$ use singular value decomposition to decompose $$Y^{(s)} =  U^{(s)}DV^{T(s)}$$ where $D$ is a diagonal matrix of the singular values, $U$ is the left singular vectors of $Y$ and $V$ is the right singular vectors of $Y$. 

The Eckart-Young-Mirsky (EYM) Theorem provides the best rank-k approximation for the missing values in $Y^{(s+1)}$. Recall $Y[M]$ represents all of the missing values of $Y$. Applying the EYM theorem:  $$Y^{(s+1)}[M] = (U[,1:k]^{(s)}D[,1:k]V[,1:k]^{T(s)})[M]$$. Eliminate (s), (s+1)

Where $U[,1:k]$ represents the first $k$ columns of $U$. 

The EYM rank approximation is repeated until the relative difference between $Y^{(s+1)}$ and $Y^{(s)}$ falls below a set threshold, $T$. The relative difference threshold is expressed: $$\|Y^{(s+1)}-Y^{(s)}\|_2 < T$$ divide by current value of Y^({s}). Make criteria invariate to a scale change, multiplyng by 20 doesnt change convergence criteria. Frobenius norm? L2 norm? 

To assess the quality of the imputation, Leave-One-Out Cross Validation (LOOCV) is used to generate a prediction error. LOOCV requires taking an observed value, setting it to NA (missing), and then performing the described imputation process. The prediction error can then be calculated as some function of the difference between the imputed value and the true value, $\hat y_{i,j} - y_{i,j}$.

Least squares estimate with gaussian error model, for the same variance assumption between cells.

What would a good statistical model be for variable frequency

AMMI Model, $$y_{ijk}`sim .mu + a_i + b_j + u_i^TDv_j+\sigma_{ij}\epsilon_{ij}$$ epsilon is standard normal so it turns the whole term to having variance i,j

```{r,eval=FALSE}
#matrix parameters
n_Sport = 20
n_Dport = 20

#get freqs
Sport_table = as.data.frame(table(argus$Sport))
Sport_table = Sport_table[order(-Sport_table$Freq),]
top_Sport = (head(Sport_table$Var1, n_Sport))

#get freqs
Dport_table = as.data.frame(table(argus$Dport))
Dport_table = Dport_table[order(-Dport_table$Freq),]
top_Dport = (head(Dport_table$Var1, n_Dport))

#create starting matrices
ports_combo_matrix = matrix(list(), nrow = n_Sport, ncol = n_Dport)
dimnames(ports_combo_matrix) = list(top_Sport, top_Dport)

ports_freq_matrix = matrix(0, nrow = n_Sport, ncol = n_Dport)
dimnames(ports_freq_matrix) = list(top_Sport, top_Dport)

nscore = function(x) {
  nscore = qqnorm(x, plot.it = FALSE)$x  # normal score 
  trn.table = data.frame(x=sort(x),nscore=sort(nscore))
  return (list(nscore=nscore, trn.table=trn.table))
}

#fill the ports_combo_matrix and ports_freq_matrix
for (s in 1:n_Sport){
  for (d in 1:n_Dport){
    combination = argus[is.element(argus$Sport, top_Sport[s])
                        & is.element(argus$Dport, top_Dport[d]),]
    obs = combination$SrcBytes
    n_obs = length(obs) #ignores NA values
    if (n_obs > 0){
      #obs = nscore(obs)$nscore #normal transformation
      for (i in 1:n_obs){
        ports_combo_matrix[[s,d]] = c(ports_combo_matrix[[s,d]],obs[i]) 
        #O(1) time to append values to a list?
        ports_freq_matrix[s,d] = ports_freq_matrix[s,d] + 1
      }
    }
  }
}

#create mean and variance matrix
ports_mean_matrix = matrix(NA, nrow = n_Sport, ncol = n_Dport)
dimnames(ports_mean_matrix) = list(top_Sport, top_Dport)

ports_variance_matrix = matrix(NA, nrow = n_Sport, ncol = n_Dport)
dimnames(ports_variance_matrix) = list(top_Sport, top_Dport)

#fill mean and variance matrix
for (s in 1:n_Sport){
  for (d in 1:n_Dport){
    if (ports_freq_matrix[s,d] == 1){
      ports_mean_matrix[s,d] = ports_combo_matrix[[s,d]]
      ports_variance_matrix[s,d] = 0
    }
    else if (ports_freq_matrix[s,d] > 1){
      ports_mean_matrix[s,d] = mean(ports_combo_matrix[[s,d]])
      ports_variance_matrix[s,d] = var(ports_combo_matrix[[s,d]])
    }
  }
}

#untuned ALS using softimpute
fit = softImpute(ports_mean_matrix,rank.max=2,lambda=0.9,trace=TRUE,type="als")
fit$d
filled = complete(ports_mean_matrix, fit)
plot(ports_mean_matrix[!is.na(ports_mean_matrix)], filled[!is.na(ports_mean_matrix)])
plot(ports_mean_matrix[!is.na(ports_mean_matrix)], filled[!is.na(ports_mean_matrix)], 
     xlim = c(0,5000), ylim = c(0,5000))


####Eckhart Young Theorem Implementation, Best Rank k Approximation####
S = 1000
k = 2
Y = ports_mean_matrix

#calculate overall mean
n = 0
sum = 0
for (s in 1:n_Sport){
  for (d in 1:n_Dport){
    if (ports_freq_matrix[s,d] != 0){
      sum = sum + ports_mean_matrix[s,d]
      n = n + ports_freq_matrix[s,d]
    }
  }
}
overall_mean = sum/n
#calculate row means and col means
row_means = rowMeans(ports_mean_matrix, na.rm = TRUE)
col_means = colMeans(ports_mean_matrix, na.rm = TRUE)

#Fill in missing values in Y with ANOVA
for (s in 1:n_Sport){
  for (d in 1:n_Dport){
    if (ports_freq_matrix[s,d] == 0){
      Y[s,d] = row_means[s] + col_means[d] - overall_mean
    }
  }
}

for (i in 1:S){
  #extract SVD
  svd_Y = svd(Y)
  D = diag(svd_Y$d)
  U = svd_Y$u
  V = svd_Y$v
  #EYM theorem
  EYM = U[,1:k] %*% D[,1:k] %*% V[,1:k]
  #replace imputed values with new values 
  for (s in 1:n_Sport){
    for (d in 1:n_Dport){
      if (ports_freq_matrix[s,d] == 0){
        Y[s,d] = EYM[s,d]
      }
    }
  }
}
```


<!-- ```{r include_packages_2, include = FALSE} -->
<!-- # This chunk ensures that the thesisdowndss package is -->
<!-- # installed and loaded. This thesisdowndss package includes -->
<!-- # the template files for the thesis and also two functions -->
<!-- # used for labeling and referencing -->
<!-- if(!require(devtools)) -->
<!--   install.packages("devtools", repos = "http://cran.rstudio.com") -->
<!-- if(!require(dplyr)) -->
<!--     install.packages("dplyr", repos = "http://cran.rstudio.com") -->
<!-- if(!require(ggplot2)) -->
<!--     install.packages("ggplot2", repos = "http://cran.rstudio.com") -->
<!-- if(!require(ggplot2)) -->
<!--     install.packages("bookdown", repos = "http://cran.rstudio.com") -->
<!-- if(!require(thesisdowndss)){ -->
<!--   library(devtools) -->
<!--   devtools::install_github("mine-cetinkaya-rundel/thesisdowndss") -->
<!--   } -->
<!-- library(thesisdowndss) -->
<!-- flights <- read.csv("data/flights.csv") -->
<!-- ``` -->


<!-- # Tables, Graphics, References, and Labels {#ref-labels} -->

<!-- ## Tables -->

<!-- In addition to the tables that can be automatically generated from a data frame in **R** that you saw in [R Markdown Basics] using the `kable` function, you can also create tables using _pandoc_. (More information is available at <http://pandoc.org/README.html#tables>.)  This might be useful if you don't have values specifically stored in **R**, but you'd like to display them in table form.  Below is an example.  Pay careful attention to the alignment in the table and hyphens to create the rows and columns. -->

<!-- ---------------------------------------------------------------------------------- -->
<!--   Factors                    Correlation between Parents & Child      Inherited -->
<!-- ------------------------- ----------------------------------------- -------------- -->
<!--   Education                                -0.49                         Yes -->

<!--   Socio-Economic Status                     0.28                        Slight    -->

<!--   Income                                    0.08                          No -->

<!--   Family Size                               0.18                        Slight -->

<!--   Occupational Prestige                     0.21                        Slight -->
<!-- ------------------------- ----------------------------------------- -------------- -->
<!-- Table: (\#tab:inher) Correlation of Inheritance Factors for Parents and Child  -->

<!-- We can also create a link to the table by doing the following: Table \@ref(tab:inher).  If you go back to [Loading and exploring data] and look at the `kable` table, we can create a reference to this max delays table too: Table \@ref(tab:maxdelays). The addition of the `(\#tab:inher)` option to the end of the table caption allows us to then make a reference to Table `\@ref(tab:label)`. Note that this reference could appear anywhere throughout the document after the table has appeared.   -->

<!-- <!-- We will next explore ways to create this label-ref link using figures. --> -->

<!-- \clearpage -->

<!-- <!-- clearpage ends the page, and also dumps out all floats. -->
<!--   Floats are things like tables and figures. --> -->


<!-- ## Figures -->

<!-- If your thesis has a lot of figures, _R Markdown_ might behave better for you than that other word processor.  One perk is that it will automatically number the figures accordingly in each chapter.    You'll also be able to create a label for each figure, add a caption, and then reference the figure in a way similar to what we saw with tables earlier.  If you label your figures, you can move the figures around and _R Markdown_ will automatically adjust the numbering for you.  No need for you to remember!  So that you don't have to get too far into LaTeX to do this, a couple **R** functions have been created for you to assist.  You'll see their use below. -->

<!-- <!-- -->
<!-- One thing that may be annoying is the way _R Markdown_ handles "floats" like tables and figures (it's really \LaTeX's fault). \LaTeX\ will try to find the best place to put your object based on the text around it and until you're really, truly done writing you should just leave it where it lies. There are some optional arguments specified in the options parameter of the `label` function.  If you need to shift your figure around, it might be good to look here on tweaking the options argument:  <https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions> -->

<!-- If you need a graphic or tabular material to be part of the text, you can just put it inline. If you need it to appear in the list of figures or tables, it should be placed in a code chunk. -->
<!-- --> -->


<!-- In the **R** chunk below, we will load in a picture stored as `duke.png` in our main directory.  We then give it the caption of "Duke logo", the label of "dukelogo", and specify that this is a figure.  Make note of the different **R** chunk options that are given in the R Markdown file (not shown in the knitted document). -->

<!-- ```{r dukelogo, fig.cap="Duke logo"} -->
<!-- include_graphics(path = "figure/duke.png") -->
<!-- ``` -->

<!-- Here is a reference to the Duke logo: Figure \@ref(fig:dukelogo).  Note the use of the `fig:` code here.  By naming the **R** chunk that contains the figure, we can then reference that figure later as done in the first sentence here.  We can also specify the caption for the figure via the R chunk option `fig.cap`. -->

<!-- \clearpage  -->

<!-- <!-- starts a new page and stops trying to place floats such as tables and figures --> -->

<!-- Below we will investigate how to save the output of an **R** plot and label it in a way similar to that done above.  Recall the `flights` dataset from Chapter \@ref(rmd-basics).  (Note that we've shown a different way to reference a section or chapter here.)  We will next explore a bar graph with the mean flight departure delays by airline from Portland for 2014.  Note also the use of the `scale` parameter which is discussed on the next page. -->

<!-- ```{r delaysboxplot, warnings=FALSE, messages=FALSE, fig.cap="Mean Delays by Airline", fig.width=6} -->
<!-- flights %>% group_by(carrier) %>% -->
<!--   summarize(mean_dep_delay = mean(dep_delay)) %>% -->
<!--   ggplot(aes(x = carrier, y = mean_dep_delay)) + -->
<!--   geom_bar(position = "identity", stat = "identity", fill = "red") -->
<!-- ``` -->

<!-- Here is a reference to this image: Figure \@ref(fig:delaysboxplot). -->

<!-- A table linking these carrier codes to airline names is available at <https://github.com/ismayc/pnwflights14/blob/master/data/airlines.csv>. -->

<!-- \clearpage -->

<!-- Next, we will explore the use of the `out.extra` chunk option, which can be used to shrink or expand an image loaded from a file by specifying `"scale= "`. Here we use the mathematical graph stored in the "subdivision.pdf" file. -->

<!-- ```{r subd, results="asis", echo=FALSE, fig.cap="Subdiv. graph", out.extra="scale=0.75"} -->
<!-- include_graphics("figure/subdivision.pdf") -->
<!-- ``` -->

<!-- Here is a reference to this image: Figure \@ref(fig:subd).  Note that `echo=FALSE` is specified so that the **R** code is hidden in the document. -->

<!-- **More Figure Stuff** -->

<!-- Lastly, we will explore how to rotate and enlarge figures using the `out.extra` chunk option.  (Currently this only works in the PDF version of the book.) -->

<!-- ```{r subd2, results="asis", echo=FALSE, out.extra="angle=180, scale=1.1", fig.cap="A Larger Figure, Flipped Upside Down"} -->
<!-- include_graphics("figure/subdivision.pdf") -->
<!-- ``` -->

<!-- As another example, here is a reference: Figure \@ref(fig:subd2).   -->

<!-- ## Footnotes and Endnotes -->

<!-- You might want to footnote something. ^[footnote text] The footnote will be in a smaller font and placed appropriately. Endnotes work in much the same way. -->

<!-- ## Bibliographies -->

<!-- Of course you will need to cite things, and you will probably accumulate an armful of sources. There are a variety of tools available for creating a bibliography database (stored with the .bib extension).  In addition to BibTeX suggested below, you may want to consider using the free and easy-to-use tool called Zotero.  The Duke librarians have created Zotero documentation at <https://library.duke.edu/research/zotero>.  In addition, a tutorial is available from Middlebury College at <http://sites.middlebury.edu/zoteromiddlebury/>. -->

<!-- _R Markdown_ uses _pandoc_ (<http://pandoc.org/>) to build its bibliographies.  One nice caveat of this is that you won't have to do a second compile to load in references as standard LaTeX requires. To cite references in your thesis (after creating your bibliography database), place the reference name inside square brackets and precede it by the "at" symbol.  For example, here's a reference to a book about worrying:  [@Molina1994].  This `Molina1994` entry appears in a file called `thesis.bib` in the `bib` folder.  This bibliography database file was created by a program called BibTeX.  You can call this file something else if you like (look at the YAML header in the main .Rmd file) and, by default, is to placed in the `bib` folder.   -->

<!-- For more information about BibTeX and bibliographies, see the following documentation from Reed College at (<http://web.reed.edu/cis/help/latex/index.html>)^[@reedweb2007]. There are three pages on this topic:  _bibtex_ (which talks about using BibTeX, at <http://web.reed.edu/cis/help/latex/bibtex.html>), _bibtexstyles_ (about how to find and use the bibliography style that best suits your needs, at <http://web.reed.edu/cis/help/latex/bibtexstyles.html>) and _bibman_ (which covers how to make and maintain a bibliography by hand, without BibTeX, at <http://web.reed.edu/cis/help/latex/bibman.html>). The last page will not be useful unless you have only a few sources. -->

<!-- If you look at the YAML header at the top of the main .Rmd file you can see that we can specify the style of the bibliography by referencing the appropriate csl file.  You can download a variety of different style files at <https://www.zotero.org/styles>.  Make sure to download the file into the csl folder. -->

<!-- **Tips for Bibliographies** -->

<!-- - Like with thesis formatting, the sooner you start compiling your bibliography for something as large as thesis, the better. Typing in source after source is mind-numbing enough; do you really want to do it for hours on end in late April? Think of it as procrastination. -->
<!-- - The cite key (a citation's label) needs to be unique from the other entries. -->
<!-- - When you have more than one author or editor, you need to separate each author's name by the word "and" e.g. `Author = {Noble, Sam and Youngberg, Jessica},`. -->
<!-- - Bibliographies made using BibTeX (whether manually or using a manager) accept LaTeX markup, so you can italicize and add symbols as necessary. -->
<!-- - To force capitalization in an article title or where all lowercase is generally used, bracket the capital letter in curly braces. -->

<!-- ## Anything else? -->

<!-- If you'd like to see examples of other things in this template, please contact Mine Cetinkaya-Rundel (email <mine@stat.duke.edu>) with your suggestions. We love to see people using _R Markdown_ for their theses, and are happy to help. -->
